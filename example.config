// Â© EMBL-European Bioinformatics Institute, 2023
// Update example nextflow config file for the BENGAL pipeline
// Yuyao Song <ysong@ebi.ac.uk>
// Oct 2023

// sections marked with CHANGE_PER_RUN should be adjusted per execution
// sections marked with CHANGE_PER_SETUP should be adjusted for each new setup on the cluster, etc.

// CHANGE_PER_RUN: directories for project root, work and results 

projectDir='/some/path/NEXTFLOW/BENGAL' // containing this repo pulled
workDir='/some/path/work'
params.results='/some/path/results'

// CHANGE_PER_RUN: params specific to dataset, please change according to your task
// input variables

// if each data is batchy, set batch_key to actual batch
// if each data does not appear bachy and cell type between batches are balanced, set batch_key to species_key

// which column stores batch to integrate
params.batch_key='species'

// which column stores species names
params.species_key='species'

// which column specifies cell types matched between species
params.cluster_key='cell_ontology_mapped'

// which column stores cell types to perform SCCAF assessment, usually same with cluster_key
params.cluster_key_sccaf='cell_ontology_mapped'

// which column stores cell types to perform SCCAF annotation transfer, usually same with cluster_key
params.projection_key_sccaf='cell_ontology_mapped'

// input metadata file that maps species names to the respective raw count .h5ad files
params.input_metadata='/some/path/data/heart_hs_mf_metadata_nf.tsv'

// set task name to metadata file basename
params.task_name='heart_hs_mf_metadata_nf'

// CHANGE_PER_SETUP: the sceasy, scvi and scib conda env that is prepared
params.sceasy_conda='/some/conda/path/anaconda3/envs/sceasy'
params.scvi_conda='/some/conda/path/anaconda3/envs/scvi-tools'
params.scib_conda='/some/conda/path/anaconda3/envs/scib'


// Only if running trajectory conservation score
//params.root_cell = 'Blastula'

// CHANGE_PER_SETUP: cluster execution

process.executor = 'lsf'
executor {
    name = 'lsf'
    queueSize = 2000
}

// enable use of conda envs
conda.enabled = true

// CHANGE_PER_SETUP: singularity container paths and cluster resource options

singularity {
    enabled = true
}

process {
    withLabel: validate {
        container = "/some/path/Singularity/CONTAINERS/CROSS_SPECIES/bengal_py.sif"
    }
    withLabel: concat {
        container = "/some/path/Singularity/CONTAINERS/CROSS_SPECIES/bengal_concat.sif"
    }
    withLabel: convert {
        conda = "${params.sceasy_conda}"
    }
    withLabel: scanpy_based {
        container = "/some/path/Singularity/CONTAINERS/CROSS_SPECIES/bengal_py.sif"
    }
    withLabel: 'seurat_based|R_based' {
        container = "/some/path/Singularity/CONTAINERS/CROSS_SPECIES/bengal_seurat.sif"
    }
    withLabel: scvi_based {
        conda = "${params.scvi_conda}"
    }
    withLabel: scIB_based {
        conda = "${params.scib_conda}"
    }
    withLabel: sccaf {
        container = "/some/path/Singularity/CONTAINERS/CROSS_SPECIES/bengal_sccaf.sif"
    }
    withLabel: regular_resource {
        cpus = 4
        queue = 'research'
        memory = '50GB'
        cache = 'lenient'
    }
    withLabel: regular_intg_resource {
        cpus = 12
        queue = 'research'
        memory = '200GB'
        cache = 'lenient'
    }
    withLabel: bigmem_intg_resource {
        cpus = 12
        queue = 'bigmem'
        memory = '400GB'
        cache = 'lenient'
    }
   withLabel: GPU_intg_resource {
        queue = 'gpu'
        clusterOptions = ' -gpu "num=2:j_exclusive=no" -P gpu -n 4 '
        memory = '50GB'
        cache = 'lenient'
    }

}


// params for pipeline, no need to change from here onwards

params.liger_metadata="${params.results}/results/rligerUINMF/h5ad_homology_concat/${params.task_name}_liger.tsv"
params.homology_concat_h5ad="${params.results}/results/h5ad_homology_concat/*.h5ad"
params.homology_concat_rds="${params.results}/results/h5ad_homology_concat/*.rds"
params.integrated_h5ad="${params.results}/results/*/cross_species/integrated_h5ad/*.h5ad"
params.integrated_rds="${params.results}/results/*/cross_species/integrated_h5ad/*.rds"

// nextflow trace settings, get run stats by adding -with-trace upon execution

trace {
    enabled = true
    file = "${params.results}/nf_trace/${params.task_name}_trace.txt"
    fields = 'task_id,hash,native_id,name,status,exit,submit,duration,realtime,%cpu,peak_rss,peak_vmem,rchar,wchar'
}

